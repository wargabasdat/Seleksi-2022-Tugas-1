{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d324749-abb1-42ff-ac47-112c5cc6018e",
   "metadata": {},
   "source": [
    "# Muhamad Fikri Nurohman / 18220097\n",
    "## Tugas 1 Calon Asisten Basis Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c25e05-7d2d-4fff-b656-547fe238f9ac",
   "metadata": {},
   "source": [
    "Deskripsi data : Data yang diambil adalah data produk TWS (True Wireless Stereo) dari situs amazon.com.\n",
    "Beberapa informasi yang diambil terkait produk adalah nama, harga semula, harga setelah diskon, persentase diskon, rating, jumlah review, dan url produk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e7ac2-63c4-4745-90a2-338b49cd6288",
   "metadata": {},
   "source": [
    "1. Import library yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de51d81-d6d8-44b6-a141-951f0f531e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de6f0a-3db9-4b05-b1f5-b2680333805d",
   "metadata": {},
   "source": [
    "2. Membuat fungsi get_url.\n",
    "Fungsi ini menerima argumen search_term yang merupakan kata kunci yang akan digunakan untuk men-generate URL. URL tersebut kemudian akan dipakai untuk mengambil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f1c819-4ed5-4f60-b1dc-dd2087c448c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(search_term):\n",
    "    template = 'https://www.amazon.com/s?k={}&i=electronics&rh=n%3A172541&qid=1656312774&ref=sr_pg_1'\n",
    "    \n",
    "    search_term = search_term.replace(' ', '+')\n",
    "    \n",
    "    url = template.format(search_term)\n",
    "    \n",
    "    url += '&page={}'\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b502a4ee-a6a3-4974-bc9c-e39e6716170e",
   "metadata": {},
   "source": [
    "3. Membuat prosedur extract_record.\n",
    "Prosedur ini menerima argumen berupa item yang akan diambil data-data yang diperlukannya. Item tersebut masih berupa html tag dan diproses sedemikian sehingga data-data yang diperlukan terkait produk TWS dari situs amazon.com dapat disimpan dalam variabel-variabel tertentu. Kumpulan data tersebut kemudian dijadikan sebuah array of data yang diperlukan (dalam hal ini variabel result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48da520-efcf-4733-aa2c-0465970bad34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record(item):\n",
    "    \n",
    "    #1. Mengambil data nama dan url produk\n",
    "    atag = item.h2.a\n",
    "    name = atag.text.strip()\n",
    "    url = 'https://www.amazon.con'+atag.get('href')\n",
    "    \n",
    "    #2. Mengambil data persentase diskon produk\n",
    "    try:\n",
    "        discount_percentage = item.find('span', {'class': 'a-size-extra-large s-color-discount s-light-weight-text'}).text\n",
    "        discount_processed = discount_percentage[1:]\n",
    "        discount = float(discount_processed[:-1])\n",
    "    except AttributeError:\n",
    "        discount_percentage = '0%'\n",
    "        discount = 0\n",
    "    \n",
    "    #3. Mengambil data harga setelah diskon produk\n",
    "    try:\n",
    "        price_parent = item.find('span', 'a-price')\n",
    "        dcp = price_parent.find('span', 'a-offscreen').text\n",
    "        discount_price = float(dcp[1:])     \n",
    "    except AttributeError:\n",
    "        return\n",
    "        \n",
    "    #4. Mengambil data harga sebelum diskon produk\n",
    "    if discount == 0:\n",
    "        normal_price = discount_price\n",
    "    else:\n",
    "        try:\n",
    "            normal_price_parent = item.find('span', {'class': 'a-price a-text-price'})\n",
    "            np = normal_price_parent.find('span', 'a-offscreen').text\n",
    "            normal_price = float(np[1:])\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    \n",
    "    #5. Mengambil data rating dan jumlah review produk\n",
    "    try:\n",
    "        rating = item.i.text\n",
    "        review = item.find('span', {'class': 'a-size-base s-underline-text'}).text\n",
    "        review_processed = review.replace(\",\", \"\")\n",
    "        review_count = int(review_processed)\n",
    "    except AttributeError:\n",
    "        rating = ''\n",
    "        review_count = 0\n",
    "        \n",
    "    if rating != \"\":\n",
    "        rating_clear = rating.split()[0]\n",
    "        rating_in_float = float(rating_clear)\n",
    "    else:\n",
    "        rating_in_float = 0\n",
    "    \n",
    "    result = (name, normal_price, discount_price, discount, rating_in_float, review_count, url)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb67212e-7596-44ee-be4b-3880494690e8",
   "metadata": {},
   "source": [
    "5. Membuat prosedur csv_to_json.\n",
    "Prosedur ini digunakan untuk mengubah data-data pada sebuah file csv menjadi bentuk Javascript Object Notation (JSON). Hal ini diperlukan karena hasil scraping pada kode yang saya buat adalah berbentuk csv. Jadi, prosedur ini diperlukan untuk mendapatkan hasil dalam bentuk json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c568201e-e3fd-4faf-9a1e-8f6659bb4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_json(csvFilePath, jsonFilePath):\n",
    "    jsonArray = []\n",
    "      \n",
    "    #Menulis file csv\n",
    "    with open(csvFilePath, encoding='utf-8') as csvf: \n",
    "        #Me-load file csv menggunakan library dictionary reader\n",
    "        csvReader = csv.DictReader(csvf) \n",
    "\n",
    "        #Mengubah setiap baris csv menjadi dictionary python\n",
    "        for row in csvReader: \n",
    "            #Menambah python dictionary ini ke array jsonArray\n",
    "            jsonArray.append(row)\n",
    "  \n",
    "    #Mengubah jsonArray menjadi JSON String dan menulis ke dalam file\n",
    "    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf: \n",
    "        jsonString = json.dumps(jsonArray, indent=4)\n",
    "        jsonf.write(jsonString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f5a5ce-be11-4d2c-b1aa-9d16258ce065",
   "metadata": {},
   "source": [
    "6. Membuat fungsi main.\n",
    "Fungsi ini dapat dikatakan sebagai program utama pada rangkaian kode pada file ini. Fungsi ini menerima argumen search_term yang merupakan kata kunci yang akan digunakan untuk men-generate URL. Hasil dari fungsi main ini adalah berupa file csv dan json berisi data-data TWS yang diambil dari situs amazon.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b45a969-d1ad-47bc-9b6c-ab01e0127a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(search_term):\n",
    "    #Menginstall webdriver chrome untuk melakukan scraping data\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    \n",
    "    records = []\n",
    "    url = get_url(search_term)\n",
    "    \n",
    "    #Dalam hal ini, saya hanya melakukan scraping pada 30 page awal produk TWS di situs amazon.com\n",
    "    for page in range(1, 30):\n",
    "        driver.get(url.format(page))\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        results = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "        \n",
    "        #Mengekstrak data pada setiap item setelah dilakukan pencarian\n",
    "        for item in results:\n",
    "            record = extract_record(item)\n",
    "            if record:\n",
    "                records.append(record)\n",
    "    \n",
    "    #Driver harus ditutup setelah digunakan\n",
    "    driver.close()\n",
    "    \n",
    "    #Menulis csv file\n",
    "    with open('TWS_amazon.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Name', 'Normal Price (USD)', 'Discounted Price (USD)', 'Discount percentage (%)', 'Rating (out of 5 stars)', 'Review Count', 'Url'])\n",
    "        writer.writerows(records)\n",
    "    \n",
    "    #Nama file setelah melakukan scraping\n",
    "    csvFilePath = r'TWS_amazon.csv'\n",
    "    jsonFilePath = r'TWS_amazon.json'\n",
    "    \n",
    "    #Konversi csv menjadi file json\n",
    "    csv_to_json(csvFilePath, jsonFilePath)\n",
    "    \n",
    "    #Pesan di akhir proses scraping. Juga sebagai indikator banyaknya jumlah data yang diambil\n",
    "    print(\"Proses scraping berhasil\")\n",
    "    print(\"Berhasil melakukan scraping sebanyak {} data\".format(len(records)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d143da-b64f-48f8-8aa4-74592ff8e058",
   "metadata": {},
   "source": [
    "7. Melakukan pemanggilan fungsi main dengan argumen 'tws'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2368f7bb-2ae7-49fd-9287-0cfcdbae4f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 102.0.5005\n",
      "[WDM] - Get LATEST chromedriver version for 102.0.5005 google-chrome\n",
      "[WDM] - About to download new driver from https://chromedriver.storage.googleapis.com/102.0.5005.61/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\Uning Rohani\\.wdm\\drivers\\chromedriver\\win32\\102.0.5005.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses scraping berhasil\n",
      "Berhasil melakukan scraping sebanyak 819 data\n"
     ]
    }
   ],
   "source": [
    "main('tws')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
